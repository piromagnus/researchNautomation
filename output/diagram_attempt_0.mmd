graph LR
    GRPO[Group Relative Policy Optimization (GRPO)] --> SolvesLimitations[Solves PPO Limitations]
    GRPO --> GRPOMechanism[GRPO Mechanism]
    GRPO --> GRPOAdvantages[GRPO Advantages]

    SolvesLimitations --> CriticDependency[Critic Dependency in PPO]
    SolvesLimitations --> HighMemory[High Memory Usage in PPO]
    SolvesLimitations --> SensitivityValue[Sensitivity to Value Function in PPO]

    GRPOMechanism --> CriticFree[Critic-Free Approach]
    GRPOMechanism --> GroupRelativeRewards[Group Relative Rewards]
    GRPOMechanism --> KLDivergence[KL Divergence for Stability]

    GroupRelativeRewards --> MultipleOutputs[Generates Multiple Outputs per Input]
    GroupRelativeRewards --> AvgRewardBaseline[Uses Average Reward Baseline]
    GroupRelativeRewards --> RelativeAdvantage[Calculates Relative Advantages]


    GRPOAdvantages --> ReducedMemoryGRPO[Reduced Memory Consumption]
    GRPOAdvantages --> ImprovedEfficiencyGRPO[Improved Computational Efficiency]
    GRPOAdvantages --> EnhancedStabilityGRPO[Enhanced Training Stability]
    GRPOAdvantages --> ComplexTasks[Effective for Complex Tasks like Math Reasoning in LLMs]


    style GRPO fill:#f9f,stroke:#333,stroke-width:2px
    style GRPOMechanism fill:#ccf,stroke:#333,stroke-width:1px
    style GRPOAdvantages fill:#ccf,stroke:#333,stroke-width:1px
    style SolvesLimitations fill:#ccf,stroke:#333,stroke-width:1px
    style GroupRelativeRewards fill:#ddf,stroke:#333,stroke-width:1px